<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
     <title>FaceRecognition project</title>
    <link rel="stylesheet" href="../style.css">
  <link rel="icon" href="../images/logo.png" type="image/x-icon">
  <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v6.0.0-beta1/css/all.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@700&display=swap">
</head>
<body>
<div class="main-contanier">
  <nav>
    <ul>
      <li><a href="../index.html">Home</a></li>
      <li><a href="#projects">Projects</a></li>
    </ul>
  </nav>
  <div id="header">
    <div class="container">
      <div class="header-text">
        <h1><span>Face Recognition with MTCNN and VGCC_Face networks</span></h1>
        <h2>One-Shot Face Recognition Problem</h2>
        <div class="skills">
          <a href="https://github.com/lakshmi-shravya/MTCNN__VGGFace_facerec"><i class="fa-brands fa-github" ></i></a>
          <button type="button" class="skill-button">Matlab</button>
          <button class="skill-button">Neural Networks</button>
          <button class="skill-button">CNN</button>
          <button class="skill-button">Transfer Learning</button>

        </div>
        <br><br>
        <p>This project focuses on solving the one-shot face recognition problem using an experimental approach. Face recognition has always been one of the hottest topics in computer vision for decades. It is extremely useful in real-world applications, such as security, surveillance, robotics, etc. With the advanced algorithm development in computer vision, more and better methods have been proposed to address challenging face recognition problem, such as poor lighting, different facial poses, occlusions, etc.</p>
        <br><br><br>
        <h2>Problem Description</h2>
        <p>The problem involves training a computer program with only one face image per subject and then using this program to recognize the remaining face images of these subjects. A public face database containing multiple face images from 100 subjects is utilized for this purpose. The images captured under diverse conditions pose a significant challenge for accurate recognition.</p>
        <br><br>
        <h2>Approach and Models</h2>
        <p>To tackle the one-shot face recognition problem the following pretrained deep network models are used:</p>
        <ul>
          <li>Multitask Neural Network (MTCNN): Used for face detection and alignment.</li>
          <li>VGG-Face: Pretrained model employed for feature extraction.</li>
        </ul>
        <p>These models are leveraged to examine their performance in the one-sample-per-person face recognition scenario.</p>

        <br><br>
        <h2>Data Preparation</h2>
        <p>Data augmentation techniques are applied to address the limited number of images per person, enhancing representation across different illuminations and poses. Images are resized to [224,224,3] dimensions to facilitate feature extraction. Various data augmentation methods, including rotation, saturation, and brightness adjustment, are employed to generate additional instances.</p>
        <img src="imgs/preprocessing.png" width="400" height="200">

        <br><br>

        <h2>Face Recognition Pipeline</h2>
        <img src="imgs/pipeline.png" width="700" height="200">
        <p>The face recognition pipeline consists of the following steps:</p>
        <li>Face Detection and Alignment: MTCNN is utilized to detect and align faces in the images.</li>
        <img src="imgs/MTCNN.png" width="200" height="200">
        <li>Feature Extraction: The VGG-Face pretrained model is employed to extract facial features.</li>
        <img src="imgs/vgg.png" width="400" height="200">
        <li>Training: The extracted features are used to train the face recognition model.</li>
        <img src="imgs/classifier.png" width="400" height="300">
        <br><br>
        <h2>Results</h2>
        <p>The baseline method, which employs a template matching approach, achieves an accuracy of 27.53%. In comparison, the proposed method utilizing deep learning techniques achieves an accuracy of 66.79%. While the proposed method outperforms the baseline, it falls short when compared to state-of-the-art methods in the domain. Further research is recommended to explore the applicability of deep learning for face recognition, particularly in the context of preprocessing techniques when dealing with one-instance-per-person problems.</p>
      <br><br>
      </div>
    </div>
  </div>
</div>
</body>
</html>